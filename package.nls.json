{
    "language": "en",
    "plugin.name": "Light Assistant",
    "cmd.goto.settings": "Open Settings",
    "cmd.goto.config": "Open Config",
    "cmd.load.sessions": "Chat Sessions",
    "cmd.chat.new": "New Chat Session",
    "desc.displayInfoMessage": "Whether to display introductory information in a new chat session.",
    "desc.sendRequestShortcut": "Set the shortcut key for sending message.",
    "desc.loadLastChatSession": "Whether to load the last chat session when the extension is started.",
    "desc.codeHighlightTheme": "Set the theme for code highlighting. **This will take effect after restarting the plugin.**",
    "desc.maxChatHistory": "The maximum number of chat sessions allowed to be saved. `-1` indicates unlimited (not recommended).",

    "ts.deleteSession": "Delete Session",
    "ts.fetchingModelInfo": "Fetching the response from model, please try again later.",
    "ts.loadChatSessionError": "Error loading chat session:",
    "ts.createdConfig": "Config file created:",
    "ts.parsingConfigError": "Error parsing config file:",
    "ts.modelNameError": "Model name is too long! Please make sure it is less than 128 characters.",
    "ts.modelTitleError": "Model title is too long! Please make sure it is less than 128 characters.",
    "ts.modelNotSelected": "No model selected, please select a model first.",
    "ts.unexpectedModelError": "Error: unexpected model type. Check your config file.",
    "ts.requestFailed": "Request failed:",

    "html.title.deleteModel": "Delete Model",
    "html.title.addModel": "Add Model",
    "html.desc.addOpenai": "The model you provided needs to be compatible with the <a href=\"https://github.com/openai/openai-node\">OpenAI API</a>.",
    "html.desc.addOllama": "Please confirm that you have installed <a href=\"https://ollama.com/\">Ollama</a> locally and configured the corresponding model.",
    "html.btn.yes": "Yes",
    "html.btn.no": "No",
    "html.btn.submit": "Submit",
    "html.btn.cancel": "Cancel",
    "html.label.textarea": "Enter content here...",
    "html.label.addModel": "Add Model",
    "html.label.loadConfig": "Load Config",
    "html.label.selectModel": "Select Model",
    "html.label.addContext": "Add Context",

    "js.reasoningContent": "reasoning content",
    "js.copy": "copy",
    "js.stopGeneration": "stop generation",
    "js.selected": "[Selected Content]",
    "js.deleteChatSession": "delete message",
    "js.selectModel": "Select Model",
    "js.confirmDelete": "Are you sure you want to delete this model?",
    "js.welcomeMessage": "<think>\n\nSome models (e.g., DeepSeek) will generate reasoning content before answering questions. The generated reasoning content can be viewed or hidden by clicking the \"reasoning content\" option in the upper right corner.\n\n</think>\n\nWelcome to Light Assistant, an open-source lightweight intelligent assistant plugin designed specifically for VS Code. As an IDE intelligent assistant developed by one person, Light Assistant aims to provide you with a simple and personalized development assistance experience.\n\n- Flexible Model Configuration\n- Chat History Management\n- Mathematical Formula Rendering\n\n---\n\nFor more information, please refer to [User Manual](https://github.com/HiMeditator/light-assistant/blob/main/docs/user-manual.md) or visit the [GitHub page](https://github.com/HiMeditator/light-assistant).\n"
}